{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TestGoogleColab",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPtoTBzQFTJGswOZP0SMBxP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dejavu3750/Blender-3D-By-Example-Second-Edition/blob/master/TestGoogleColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "octa6Pfodvv9",
        "outputId": "92549a14-9538-4aa7-e478-3b87e59c5e95"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "print(torch.__version__)\n",
        "gpu_avail = torch.cuda.is_available()\n",
        "print(f\"Is the GPU available? {gpu_avail}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9.0+cu102\n",
            "Is the GPU available? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAfO1j1SfX_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70db49c2-a2cc-4cf5-ffbd-ec0af9a7716e"
      },
      "source": [
        "# Push a tensor to a device object\n",
        "# Depend on your system.\n",
        "# Point to GPU if you have one, and otherwise to the CPU\n",
        "# Then, you can write your code with respect to this device object, and it\n",
        "# allows you to run the same code on both CPU-only system, and one with\n",
        "# a GPU\n",
        "device  = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)\n",
        "\n",
        "# Create a tensor and push it to the device\n",
        "x = torch.zeros(2,3)\n",
        "x = x.to(device)\n",
        "print(\"X\", x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device cuda\n",
            "X tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsE_HX1QiaJP",
        "outputId": "e0dadbe6-9fe6-46f0-8780-9c9fb067eace"
      },
      "source": [
        "import time\n",
        "\n",
        "# Test runtime on CPU for large matrix multiplication\n",
        "x = torch.randn(5000, 5000)\n",
        "\n",
        "# CPU version\n",
        "start_time = time.time()\n",
        "_ = torch.matmul(x, x)\n",
        "end_time = time.time()\n",
        "print(f\"CPU time: {(end_time - start_time):6.5f}s\")\n",
        "\n",
        "# GPU version\n",
        "x = x.to(device)\n",
        "# The first operation on a CUDA device can be slow as it has to establish a\n",
        "# CPU-GPU commucation first.\n",
        "# Hence, we run an arbitrary command first without timing it for a fair comparison\n",
        "if torch.cuda.is_available():\n",
        "    _ = torch.matmul(x*0.0, x)\n",
        "\n",
        "start_time = time.time()\n",
        "_ = torch.matmul(x, x)\n",
        "end_time = time.time()\n",
        "print(f\"GPU time: {(end_time - start_time):6.5f}s\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU time: 3.37753s\n",
            "GPU time: 0.00014s\n"
          ]
        }
      ]
    }
  ]
}